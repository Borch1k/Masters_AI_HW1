# Masters_AI_HW1

1. lets address pickle-sized elephant in a room, в целом все файлы можно было бы объединить, но я решил их поделить на логические блоки, поэтому их 3
2. Все файлы для запуска streamlit приложения пересоздадутся если выполнить все ячейки в ipynb

## Теперь о домашке

Анализа было много, ноутбук я держал открытым 3 дня, под конец он даже начал лагать при просмотре, что со мной случается впервые

### Что сделано?
1. EDA.1
  - Во-первых я впервые узнал о ydata, это в целом вполне удобно, с точки зрения отношения количества кода к количеству анализа
  - Пришлось посмотреть на статистики о машинах в сети, чтобы начать понимать о чём идёт речь в различных столбцах
  - В целом первый блок задач в основном на работу с пропусками, и не особо с анализом, но это тоже важный шаг, пропуски особо не повлияли на распределения, что ожидаемо
2. EDA.2
  - Парсинг значений, это было интересно, на данные пришлось несколько раз посмотреть, увидеть как формируются значения, особенно пересчитать между единицами измерений
  - Судя по чатам я не заметил, что mileage имеет не один вид размерности, так что тут можно было тоже написать функцию для парсинга и пересчёта
  - Нашёл там один объект который мне ломал всякие визуализации, оказалось, что скорее всего ему почему-то torque записали в 10 раз больше, чем должно быть, что ончеь странно
3. EDA.3
  - Визуализации, первые предположения о корреляциях, на этот график я смотрел периодически в течении двух дней, чтобы сравнивать дальнейшие результаты
  - Тут появилась идея о связи всех параметров мотора, как физической переменной, было бы интересно попробовать построить эту скрытую переменную, но у меня ни сил, ни времени нет
  - Тут так же численный анализ корреляций
  - Ну и самописный спирмен, пришлось поизучать разные сайты, чтобы найти адекватную формулировку для полного расчёта с совпадающими рангами, но нашёл формулу, написал
  - phik я честно до конца не понял, потому что конечно он показывает какую-то связь категориальных переменных и вещественных, но узнать что это за связь нельзя, как и узнать о характере связи (положительная/отрицательная) + почему-то km_driven потерял связь, в общем тут много вопросов и мало ответов
  - На визуализацию сил не осталось
  - (это был первый полный день работы над домашкой)
4. Model.1
  - Модели, эта часть пошла быстрее и легче
  - Самописные $R^2$ - все формулы с wikipedia
  - Скейл значений особо не привёл к улучшению, но да, он больше для интерпретируемости нужен, так как параметры используются на одних и тех же стандартных распределениях
  - С gridsearch что-то не так в задании, потому что в первый раз, не было уже созданной строчки с импортиротом в ipynb, а во второй раз, она уже была
  - Тут мне в целом понравилось строить графики и по графикам подбирать диапазон для перебора параметров
  - Самый интересный график, где для ElasticNet score разделяется
  - L0 я удивился о существовании, я не нашёл в конспектах упоминания, но после просмотра статьи от OpenAI понял, что у меня нет сил и времени это делать, странно что это задание не бонусное, хотя по моим ощущением оно должно быть бонусным
5. Model.2
  - Категориальные фичи, я потратил слишком много времени на анализ name (3+ часа), но кое-что получилось отделить
  - Трёхбуквенные слова - тут хз, но просто очень много всяких tdi, lxi, vdi, и тд., это как бы модификации моделей, но лучше выписать модификации - это было бы слишком долго
  - OHE - и тут тоже странно, что модель не попросили запустить, но я всё равно запустил, потому что дальше какие-то ещё модификации и я подумал, что лушче пусть будет datapoint до модификаций
  - Тут конечно было бы классно написать/заюзать готовый encoding который делает среднее цены по категориям, вместро OHE, но не хватило времени, зато я воспользовался полным набором того, что я выгружаю из name
  - Вообще в целом добавление категориальных параметров сильно улучшило модель, что логично
6. Business
  - Ну тут коротко и просто, на удивление, пока я чинил баги, у меня немного поменялся топ моделей, и если в первых версиях лучшей был Ridge, в последней версии лучшей стал Lasso
  - Ну самописная я думаю вполне понятна, просто небольшое расширение над изначальной метрикой + сдвиг, чтобы у нас была модель которая чаще завышает цену, это кстати можно увидеть и на графике в Streamlit
7. Streamlit
  - Честно сначала мне не понравилось на нём писать, но потом я прмвык (я просто обычно пишу на flask+html, или latex или md, и я всё ещё считаю, что для некоторых вещей они куда удобнее)
  - Как по мне получилось вполне сносно, особенно полезно, что я добавил отображение парсинга названия, так что можно сразу видеть, что мой код распознает в названии
  - я попробовал добавить pairplot из EDA, но это оказалось некрасиво и неудобно, так что я убрал его
  - Честно я не знаю, что ещё туда можно дописать
  - Особо ограничений я не заметил, но стиль написания кода мне непривычный
8. Финал
  - Рекурсия, потому что это блок, о написании этого блока
  - Честно, я бы разделил эту домашку на две, лаги при решении со мной тоже согласны
  - Домашка достаточно лёгкая (не считая L0....), но очень огромная
  - Ещё не очень прикольно в нескольких местах писать об анализе, я понимаю зачем, но учитывая что я решил streamlit делать сразу, это немножко получился перегруз
